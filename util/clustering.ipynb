{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 20180711 문의사항 clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gensim version=3.4.0\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "print('Gensim version={}'.format(gensim.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soynlp version=0.0.46\n"
     ]
    }
   ],
   "source": [
    "import soynlp\n",
    "print('Soynlp version={}'.format(soynlp.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch\n",
    "TRAIN_WORD2VEC = True\n",
    "TRAIN_DOC2VEC = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent 0: 추천인정보에 인스타아이디를 넣는건가요 아니면 로그인할때 메일주소를 넣는건가요?  \n",
      "sent 1: 제가 소개해서 가입하신분들이 인스타아이디 dlsksgml01로 추천인을 넣으셨다는데 포인트 ... \n",
      "sent 2: 안녕하세요. 지금 신청은 했는데요. 제가 처음이라.. 잘 몰라서요.  \n",
      "sent 3: 포스트 금액을 제가 설정하는 것이던데, 제가 받고 싶은 금액을 적으면 되는것인지..  \n"
     ]
    }
   ],
   "source": [
    "# 단어추출\n",
    "from soynlp.utils import DoublespaceLineCorpus\n",
    "corpus_fname = '../data/md_contactus_question.txt'\n",
    "corpus = DoublespaceLineCorpus(corpus_fname, iter_sent=True, num_sent=4)\n",
    "\n",
    "for n_sent, sent in enumerate(corpus):\n",
    "    print('sent %d: %s %s '% (n_sent, sent[:50], '' if len(sent) < 50 else '...'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs 0 (#sents= 2): 추천인정보에 인스타아이디를 넣는건가요 아니면 로그인할때 메일주소를 넣는건가요?   제가 소 ...\n",
      "docs 1 (#sents= 4): 안녕하세요. 지금 신청은 했는데요. 제가 처음이라.. 잘 몰라서요.  포스트 금액을 제가 ...\n",
      "docs 2 (#sents= 1): 알려주세요 \n"
     ]
    }
   ],
   "source": [
    "corpus = DoublespaceLineCorpus(corpus_fname, iter_sent=False, num_doc=3)\n",
    "for n_doc, doc in enumerate(corpus):\n",
    "    print('docs %d (#sents= %d): %s %s'% (n_doc, len(doc.split('  ')), doc[:50].strip(), '' if len(doc) < 50 else '...'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<soynlp.utils.utils.DoublespaceLineCorpus object at 0x0000000009C03898>\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###WordExtractor (Cohesion score, Branching Entropy, Accessor Variety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.142 Gb\n"
     ]
    }
   ],
   "source": [
    "from soynlp.word import WordExtractor\n",
    "\n",
    "corpus = DoublespaceLineCorpus(corpus_fname, iter_sent=True)\n",
    "word_extractor = WordExtractor(left_max_length=10,\n",
    "                               right_max_length=6,\n",
    "                               min_count=5)\n",
    "word_extractor.train(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " cohesion probabilities ... (1 in 7364)\r",
      "all cohesion probabilities was computed. # words = 6739\n",
      "\r",
      "all branching entropies was computed # words = 10462\n",
      "\r",
      "all accessor variety was computed # words = 10462\n"
     ]
    }
   ],
   "source": [
    "scores = word_extractor.word_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Noun extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used default noun predictor; Sejong corpus based logistic predictor\n",
      "C:/Users/mediance_ssh/Anaconda3/lib/site-packages/soynlp\n",
      "scan vocabulary ... \n",
      "done (Lset, Rset, Eojeol) = (61241, 40570, 24490)\n",
      "predicting noun score was done                                        \n",
      "before postprocessing 7587\n",
      "_noun_scores_ 1530\n",
      "checking hardrules ... done\n",
      "after postprocessing 919\n",
      "extracted 13 compounds from eojeols"
     ]
    }
   ],
   "source": [
    "from soynlp.noun import LRNounExtractor\n",
    "from soynlp.noun import NewsNounExtractor\n",
    "\n",
    "corpus = DoublespaceLineCorpus(corpus_fname, iter_sent=True)\n",
    "noun_extractor = NewsNounExtractor()\n",
    "nouns = noun_extractor.train_extract(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터 토크나이징 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['항산화', '노화방지', '머릿결']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import LTokenizer,MaxScoreTokenizer, RegexTokenizer\n",
    "\n",
    "cohesion_scores = {word:score.cohesion_forward for word, score in scores.items()}\n",
    "ltokenizer = LTokenizer(scores=cohesion_scores)\n",
    "\n",
    "ltokenizer.tokenize('항산화 노화방지 머릿결')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_fname='../data/md_contactus.txt';\n",
    "tokenized_corpus_fname=''; #토크나이징 모두 끝낸 pkl 파일...\n",
    "word2vec_fname='';\n",
    "doc2vec_fname='';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_text(fname, debug=True):\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        docs=[]\n",
    "        for i, doc in enumerate(f):\n",
    "            break\n",
    "        docs.append(doc.split('\\t'))\n",
    "    \n",
    "    title, question, answer = zip(*docs)\n",
    "    return title, question, answer\n",
    "\n",
    "title, question, answer = get_text(tokenized_corpus_fname)\n",
    "docs[:5]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
